{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Chat Stylist Implementation & Testing Walkthrough\n",
        "\n",
        "This notebook demonstrates how to configure, run, and validate the **AI Chat Stylist** project. It covers environment preparation, instantiating the stylist with or without live OpenAI access, adding optional outfit imagery, and executing automated tests.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Preparation\n",
        "\n",
        "Install the project dependencies. When running inside this repository's root directory the command below will reuse the shared `requirements.txt` file. Uncomment the cell if you have not already installed the dependencies in your environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# %pip install -r ../requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure Credentials\n",
        "\n",
        "Set the `OPENAI_API_KEY` environment variable if you plan to call the live OpenAI APIs. Without a key, the notebook automatically falls back to lightweight stub implementations so you can still explore the flow offline.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "if OPENAI_API_KEY:\n",
        "    print(\"\u2705 OPENAI_API_KEY detected \u2014 live API calls enabled.\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f OPENAI_API_KEY not found. The notebook will run in offline demo mode.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Import Project Modules\n",
        "\n",
        "Add the repository root to `sys.path` so the `ai_chat_stylist` package can be imported, then bring in the key classes. The helper below automatically swaps in stubbed dependencies when the API key is unavailable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_ROOT = Path('..').resolve()\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_ROOT))\n",
        "\n",
        "from ai_chat_stylist.chatbot import AIChatStylist, StylistConfig\n",
        "from ai_chat_stylist import chatbot as chatbot_module\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper: Build a Stylist Instance\n",
        "\n",
        "`build_notebook_stylist` returns an `AIChatStylist` configured for either live usage (when an API key exists) or deterministic offline experimentation. In offline mode it:\n",
        "\n",
        "- Substitutes a simple language model stub that produces consistent responses.\n",
        "- Replaces the outfit image description function with a quick rule-based summary.\n",
        "- Seeds the vector store with basic wardrobe guidance for retrieval demos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "class OfflineLLM:\n",
        "    \"\"\"Deterministic fallback LLM for environments without OpenAI access.\"\"\"\n",
        "\n",
        "    def invoke(self, messages):\n",
        "        human_turns = [getattr(m, 'content', '') for m in messages if getattr(m, 'type', '') == 'human']\n",
        "        prompt = human_turns[-1] if human_turns else \"your wardrobe\"\n",
        "        return AIMessage(content=(\n",
        "            \"Offline demo response: consider layering a textured cardigan with \"\n",
        "            f\"{prompt.lower()} and add an accent accessory for balance.\"\n",
        "        ))\n",
        "\n",
        "def build_notebook_stylist(system_prompt: Optional[str] = None) -> AIChatStylist:\n",
        "    config = StylistConfig()\n",
        "    if system_prompt:\n",
        "        config.system_prompt = system_prompt\n",
        "\n",
        "    if OPENAI_API_KEY:\n",
        "        return AIChatStylist(config=config)\n",
        "\n",
        "    def offline_llm_factory(cfg):\n",
        "        return OfflineLLM()\n",
        "\n",
        "    def offline_embedding_factory(cfg):\n",
        "        class DummyEmbeddings:\n",
        "            def embed_documents(self, texts):\n",
        "                return [[float(idx + 1)] * 3 for idx, _ in enumerate(texts)]\n",
        "            def embed_query(self, text):\n",
        "                return [0.0, 0.0, 0.0]\n",
        "        return DummyEmbeddings()\n",
        "\n",
        "    from langchain_community.vectorstores import FAISS\n",
        "\n",
        "    stylist = AIChatStylist(\n",
        "        config=config,\n",
        "        llm_factory=offline_llm_factory,\n",
        "        embedding_factory=offline_embedding_factory,\n",
        "        vectorstore=FAISS.from_texts(\n",
        "            [\n",
        "                \"The user prefers smart-casual looks with neutral colors.\",\n",
        "                \"They own white sneakers, dark denim, and a camel trench coat.\",\n",
        "            ],\n",
        "            embedding=offline_embedding_factory(config.vector_config),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    def offline_describe_outfit_image(image_path: str, prompt: Optional[str] = None) -> str:\n",
        "        return (\n",
        "            \"Offline summary for '{image}': neutral palette with relaxed tailoring.\"\n",
        "        ).format(image=Path(image_path).name)\n",
        "\n",
        "    chatbot_module.describe_outfit_image = offline_describe_outfit_image\n",
        "    return stylist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Instantiate the Stylist\n",
        "\n",
        "Use the helper to create the stylist instance. Adjust the optional prompt to experiment with different personalities.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "stylist = build_notebook_stylist(\n",
        "    system_prompt=\"You are a cheerful fashion expert who emphasizes comfort and versatility.\"\n",
        ")\n",
        "stylist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. (Optional) Add Outfit Imagery\n",
        "\n",
        "Provide the path to an outfit photograph to enrich the stylist's memory. In offline mode, the notebook produces a deterministic textual summary so you can verify the ingestion flow without external services.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Replace with your own image path if available.\n",
        "example_image = Path('../tests/fixtures/example_outfit.jpg')\n",
        "if example_image.exists():\n",
        "    description = stylist.add_outfit_image(str(example_image))\n",
        "    print('Image summary:', description)\n",
        "else:\n",
        "    print('No example image found. Skipping image ingestion step.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Chat with the Stylist\n",
        "\n",
        "Enter a message to test the full conversational loop. Each turn is stored in the FAISS-backed memory so subsequent interactions can reference prior wardrobe details.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "user_question = \"I'm meeting friends for brunch \u2014 what outfit should I build?\"\n",
        "response = stylist.chat(user_question)\n",
        "print('Stylist response:\n",
        "', response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inspect Stored Context\n",
        "\n",
        "Review the texts persisted to the vector store to confirm that conversations and image summaries are captured for future retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "for idx, context in enumerate(stylist.export_context(), start=1):\n",
        "    print(f\"{idx:02d}: {context}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Run Automated Tests\n",
        "\n",
        "Execute the repository's pytest suite directly from the notebook to validate the LangChain pipeline, retrieval behavior, and image ingestion flow.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pytest -q\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}